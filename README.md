# Multi-Layer-Perceptron

## Project Description
This study uses modules including the activation function, optimizer, loss function, and regularization to identify a set of variables that enhance the multi-layer perceptron modelâ€™s performance. We outline the principles of the modules and show how they affect the effectiveness of the neural network.

The principles of essential neural network modules are presented in this paper, allowing us to rebuild and extend neural network design from scratch. We can more efficiently perform hyperparameter tuning and model structuring by conducting ablation studies to investigate the impact of various modules. A refined base model that successfully manages the multi-class classification problem and can serve as a useful starting point for additional challenging datasets will also be presented. We offer suggestions for hyperparameter tuning at the conclusion.
